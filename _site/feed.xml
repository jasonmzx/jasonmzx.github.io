<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>jasonmzx | Jason Manarroo</title>
		<description>Placeholder</description>
		<link></link>
		<atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Clipmapping (Optimized "Open-World" Rendering Techniques for Games)</title>
				<description>&lt;h1 id=&quot;my-notes--qna-on-clip-mapping-various-challenges--techniques&quot;&gt;My Notes &amp;amp; QnA on Clip-Mapping; Various Challenges &amp;amp; Techniques&lt;/h1&gt;

&lt;p&gt;Clip-mapping essentially optimizes the amount of Vertices rendered on Scene, whilst still maintaining a very convincing effect of the ‚ÄúOpen-World‚Äù going all the way to the Horizon.&lt;/p&gt;

&lt;p&gt;Making the Player feel as if they are in a Huge &amp;amp; Vast World, but without having to render most of the map in it‚Äôs full detail, only what‚Äôs surrounding the player, and it gradually get‚Äôs less detailed as the distance increases &lt;em&gt;(Towards the ‚ÄúHorizon‚Äù of the viewport)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The way you‚Äôre able to see so far in the world is since the further you are from a place,Naturally the less detail you see‚Ä¶ Obviously stuff just gets far, and we looks ‚ÄúResolution‚Äù so to speak with our eyes, this kind of thing &lt;br /&gt;
can be simulated with this technique; &lt;strong&gt;Terrain Rendering Using GPU-Based Geometry Clipmaps&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/custom/pictures/clip_map1.png&quot; alt=&quot;Clip Map 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Essentially, at your player &lt;em&gt;(The Camera)&lt;/em&gt; it will render the areas closest to you with the Finest Level of detail, as you get very close to this position in the open world.&lt;/p&gt;

&lt;p&gt;Gradually as you look further out in the distance of the world, it renders a different level of detail, which is still the same map, but at a Coarser detail &lt;strong&gt;(Divided by 2, each LOD for example)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LOD&lt;/strong&gt; : Level-of-Detail, Referred to as an Entire Layer of Various Detail Level, Example the LODs far away are very coarse. The LOD nearest to the player is the finest possible.&lt;/p&gt;

&lt;p&gt;Notice how these &lt;strong&gt;LOD&lt;/strong&gt;s form rings of detail arround the player so to speak, &lt;em&gt;Square-ish Rings&lt;/em&gt; LOL&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;isnt-it-very-expensive-to-dynamically-simplify-further-away-parts-of-the-map-on-the-fly&quot;&gt;Isn‚Äôt it very expensive to dynamically simplify further away parts of the map, on the fly?&lt;/h3&gt;

&lt;p&gt;Yes, this in real-time would be computationally expensive, but given a known map, we can pre-compute all &lt;strong&gt;LOD&lt;/strong&gt; Layers &lt;em&gt;(The entire map)&lt;/em&gt; and just render the &lt;strong&gt;Rings&lt;/strong&gt; at needed positions arround the Camera&lt;/p&gt;

&lt;h4 id=&quot;-gpt4s-input&quot;&gt;ü§ñ GPT4‚Äôs Input:&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Precomputed Levels:&lt;/strong&gt; Often, multiple LODs of the terrain are precomputed. This means the finer and coarser versions are already available, and the system just needs to select which one to render based on the distance from the camera. For example, a terrain patch might have a full-resolution mesh, a half-resolution mesh, a quarter-resolution mesh, etc. These are pre-generated and stored.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Streaming and Caching:&lt;/strong&gt; Modern games and engines usually integrate LOD techniques with data streaming. The high-resolution data for distant terrains is not kept in memory but is streamed in as the player approaches. Meanwhile, coarser representations might be cached in memory for quick access.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;between-lods--ill-have-different-levels-next-to-eachother-surely-there-will-be-some-tearing-&quot;&gt;Between LODs , I‚Äôll have different ‚ÄúLevels‚Äù next to eachother, surely there will be some tearing !?!&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/custom/pictures/clip_map2.png&quot; alt=&quot;Clip Map 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Checkout the Discrepancies!&lt;/p&gt;

&lt;p&gt;To solve this, &lt;strong&gt;Transition Layers&lt;/strong&gt; are used to be, since in the Scene, we‚Äôll always know exactly where we LODs ‚Äúseam‚Äù together.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/custom/pictures/clip_map3.png&quot; alt=&quot;Clip Map 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So these &lt;strong&gt;Transition Layers&lt;/strong&gt; Can be pre-computed aswell for every possible combination of Neighbouring LODs‚Ä¶ That‚Äôs &lt;strong&gt;ALOT OF COMBOS !!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It also might be viable to just compute the transition layers on during run-time, might be an OK trade-off, to having &lt;strong&gt;Game World Maps&lt;/strong&gt; being extremely space complex?&lt;/p&gt;

&lt;h4 id=&quot;-gpt4s-input-1&quot;&gt;ü§ñ GPT4‚Äôs Input:&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Pattern-based Transitions:&lt;/strong&gt; Instead of precomputing unique transition patterns for every possible scenario, developers can precompute patterns for the basic scenarios and reuse them. For instance, if you have 4 LOD levels, you‚Äôd primarily be concerned with transitions between LOD 0-1, 1-2, and 2-3. The specific pattern or stitching used to bridge between LOD 1 and 2, for example, can be reused wherever this transition occurs in the terrain. The patterns are a representation of how one LOD can transition to another, but they don‚Äôt represent specific parts of the terrain.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dynamic Stitching:&lt;/strong&gt; Dynamic Stitching: Some engines employ methods to dynamically create the stitching between LOD levels at runtime. While this might incur a computational cost, it can save on memory and storage.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Simplification of Farthest LODs:&lt;/strong&gt; At very distant LODs, where details are minuscule on screen, terrains can be vastly simplified. Such simplifications reduce the need for intricate transition patterns since the difference between two very distant LODs might be negligible.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So I can just really simple stitching algorithms, and with such a low vertex counter between the far LODs, It‚Äôs gonna be fast asf!&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;when-looking-at-further-lod-levels-how-can-i-ensure-that-the-general-shape-keeps-its-character-features-from-afar&quot;&gt;When looking at further LOD Levels, how can I ensure that the general shape keeps it‚Äôs ‚ÄúCharacter‚Äù Features from afar?&lt;/h3&gt;
&lt;p&gt;(Example: Stoney Cliff Side Up close, But from afar it looks like a flat rock)&lt;/p&gt;

&lt;h4 id=&quot;-gpt4s-input-2&quot;&gt;ü§ñ GPT4‚Äôs Input:&lt;/h4&gt;

&lt;p&gt;This is one of the core challenges of LOD techniques: preserving the ‚Äúcharacter‚Äù or primary features of the original model as it‚Äôs simplified. If not handled properly, the terrain or object can indeed look noticeably different, or even wrong, at lower LODs. This is especially true for features like a rocky cliff-side where the intricate details and silhouette contribute significantly to its appearance.&lt;/p&gt;

&lt;p&gt;Here are some considerations and techniques related to this:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Feature Preservation:&lt;/strong&gt; Advanced; simplification of mesh algorithms aim to preserve the primary features of the model. They don‚Äôt just remove vertices arbitrarily. Instead, they prioritize vertices based on certain metrics (e.g., curvature, importance, visual saliency) to ensure that important features are preserved as long as possible.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Normal Maps:&lt;/strong&gt; To retain the appearance of details without having them in geometry, games often use normal maps. Even when the geometry is simplified, the normal map can give the illusion of those details when rendering, especially when lighting is involved. So, a cliff might lose its intricate geometry at a distance, but a normal map could still provide the appearance of those rocky details.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Dynamic &amp;amp; Continuous LOD (CLOD):&lt;/strong&gt; Some techniques don‚Äôt use discrete LOD levels but adjust the mesh continuously based on various factors like distance, screen space error, etc. This can offer smoother transitions but might be more computationally intensive.&lt;/td&gt;
      &lt;td&gt;&lt;em&gt;NOT PRE-COMPUTED!&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Adjusting by Hand:&lt;/strong&gt; In some cases, especially for crucial assets in a game, artists might manually adjust the lower LOD models to ensure they retain the desired appearance. While algorithms can do a lot, there‚Äôs sometimes no substitute for the human touch.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;great-ressources&quot;&gt;Great Ressources!&lt;/h2&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/yoUQRT-Hmcc&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href=&quot;https://hhoppe.com/proj/geomclipmap/&quot;&gt;GEO CLIPMAP | hhoppe.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.nvidia.com/gpugems/gpugems2/part-i-geometric-complexity/chapter-2-terrain-rendering-using-gpu-based-geometry&quot;&gt;developers.NVIDIA.com | GPU Gems 2&lt;/a&gt;&lt;/p&gt;

</description>
				<pubDate>Sat, 09 Sep 2023 06:00:00 -0400</pubDate>
				<link>/2023/clip-maps/</link>
				<guid isPermaLink="true">/2023/clip-maps/</guid>
			</item>
		
			<item>
				<title>React In Production</title>
				<description>&lt;h1 id=&quot;react-in-production&quot;&gt;React In Production&lt;/h1&gt;

&lt;p&gt;When it‚Äôs time to move your app to production, having multiple JavaScript or CSS files isn‚Äôt ideal. When a user visits your site, each of your files will require an &lt;em&gt;additional&lt;/em&gt; HTTP request, ~making your site slower to load.~ So to remedy this, you can create a &lt;strong&gt;‚Äúbuild‚Äù&lt;/strong&gt; of our app, which merges all your CSS files into one file, and does the same with your JavaScript. This way, you minimize the number and size of files the user gets. To create this &lt;strong&gt;‚Äúbuild‚Äù&lt;/strong&gt;, you use a &lt;strong&gt;‚Äúbuild tool‚Äù&lt;/strong&gt;. Hence the use of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm run build&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;After you run npm run build your build directory will be:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;build/
  static/
    css/
      main.css
    js/
      main.js
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(Right now, with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm start&lt;/code&gt;, the &lt;strong&gt;React Components&lt;/strong&gt; are visible, not minified &amp;amp; combined like a build)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/43830866/what-is-npm-run-build-in-create-react-app&quot;&gt;Quoted from StackOverflow&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;From my understanding, you‚Äôre essentially &lt;strong&gt;serve&lt;/strong&gt;ng a static version of your build &lt;em&gt;(A.K.A Webpack Bundle)&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;what-is-webpack-what-does-it-do-for-react-build&quot;&gt;What is Webpack, what does it do for React Build?&lt;/h3&gt;
&lt;p&gt;Webpack simplifies the build process for React applications. It allows developers to manage dependencies and bundle files with ease. Webpack can also optimize code and assets for production, reducing the file size of the application and improving performance.&lt;br /&gt;
&lt;em&gt;(Minification of JavaScript, HTML &amp;amp; CSS‚Ä¶ Making React.js Code More Obscured‚Ä¶ Bundling of Website)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Serving a React Build: &lt;em&gt;(npm &lt;strong&gt;&lt;a href=&quot;https://www.npmjs.com/package/serve&quot;&gt;Serve Library, by Vercel&lt;/a&gt;&lt;/strong&gt; required)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm install -g serve&lt;/code&gt;&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;serve -s build&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Serving React Build on specific port: &lt;em&gt;(Auto default is port 3000)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;serve -s build -l 4000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://create-react-app.dev/docs/deployment/&quot;&gt;SRC: Create-React-App Deployment Docs&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;what-if-i-dont-want-to-use-serve-and-just-deploy-the-static-site-directly-to-nginx&quot;&gt;What if I don‚Äôt want to use serve, and just deploy the Static Site directly to NGINX‚Ä¶&lt;/h2&gt;

&lt;p&gt;Dockerfile for React.js Build, without serve&lt;/p&gt;
&lt;div class=&quot;language-Dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;node:16-alpine&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;builder&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Set the working directory to /app inside the container&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WORKDIR&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; /app&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Copy app files&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; . .&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Install dependencies (npm ci makes sure the exact versions in the lockfile gets installed)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;npm ci 
&lt;span class=&quot;c&quot;&gt;# Build the app&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;npm run build

&lt;span class=&quot;c&quot;&gt;# Bundle static assets with nginx&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;nginx:1.21.0-alpine&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;production&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ENV&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; NODE_ENV production&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Copy built assets from `builder` image&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; --from=builder /app/build /usr/share/nginx/html&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Add your nginx.conf&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; nginx.conf /etc/nginx/conf.d/default.conf&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Expose port&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;EXPOSE&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; 80&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Start nginx&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;NGINX Setup, it will literally just be manually serving the ‚ÄúStatic‚Äù HTML built by React Build &amp;amp; the whole Web Pack?&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// nginx.conf

server &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  listen 80&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  location / &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    root /usr/share/nginx/html/&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    include /etc/nginx/mime.types&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    try_files &lt;span class=&quot;nv&quot;&gt;$uri&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$uri&lt;/span&gt;/ /index.html&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;look into these jason&lt;/p&gt;

&lt;p&gt;TODO: https://jsramblings.com/dockerizing-a-react-app/&lt;/p&gt;

&lt;p&gt;TODO: Look into this link https://medium.com/bb-tutorials-and-thoughts/how-to-serve-react-application-with-nginx-and-docker-9c51ac2c50ba&lt;/p&gt;

</description>
				<pubDate>Sun, 30 Jul 2023 06:00:00 -0400</pubDate>
				<link>/2023/react-in-production/</link>
				<guid isPermaLink="true">/2023/react-in-production/</guid>
			</item>
		
			<item>
				<title>Punch & Kick Tracking using Camera</title>
				<description>&lt;h2 id=&quot;kick-tracking-software&quot;&gt;Kick Tracking Software&lt;/h2&gt;

&lt;p&gt;Ideal Pipeline:&lt;/p&gt;

&lt;p&gt;1.) Camera Sensor Captures that feed into classification task&lt;br /&gt;
2.) YOLOv8 ?&lt;/p&gt;

</description>
				<pubDate>Sun, 30 Jul 2023 06:00:00 -0400</pubDate>
				<link>/2023/kick-tracker-init/</link>
				<guid isPermaLink="true">/2023/kick-tracker-init/</guid>
			</item>
		
			<item>
				<title>Stratified VS. Random Sampling</title>
				<description>&lt;h2 id=&quot;stratified-sampling&quot;&gt;Stratified Sampling:&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/custom/pictures/stratified_sampled.png&quot; alt=&quot;Stratified Sampling&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.wallstreetmojo.com/stratified-sampling/&quot;&gt;Source_for_example_1_WallStreetMojo.com&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StratifiedShuffleSplit&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StratifiedShuffleSplit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_splits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;income&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;strat_train_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;strat_test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://machine-learning-apps.github.io/hands-on-ml2/02_end_to_end_machine_learning_project&quot;&gt;Code Credits from hands-on-ml2-notebooks , CH.2&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_size&lt;/code&gt; refers to the amount of the dataset you‚Äôre sub-setting (here it‚Äôs set to 20%)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random_state&lt;/code&gt; is an optional parameter that‚Äôs great to use as static seed, and replicate a certain pattern of randomness again. &lt;em&gt;(E.G: I got 2 datasets, data and labels, with the same size and indices, I can just both Shuffle them by the same seed, and they will match!)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the &lt;strong&gt;for loop&lt;/strong&gt;, Iterating over the Stratified Split data specifically by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;income&lt;/code&gt; parameter, so it will basically sample an income distribution proportional to our dataset. &lt;em&gt;(For the the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strat_train_set&lt;/code&gt; Stratified Training Dataset, &amp;amp; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strat_test_set&lt;/code&gt; Stratified Test Dataset)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Notice how both stratified datasets have similar proportions :D&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/custom/pictures/stratified_jupyter.png&quot; alt=&quot;Output of strat_&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;random-sampling&quot;&gt;Random Sampling:&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/custom/pictures/random_sample.png&quot; alt=&quot;Random Sampling&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# For illustration only. Sklearn has train_test_split()
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;split_train_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_ratio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;shuffled_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_set_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_ratio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffled_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffled_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;This block of code is basically equivalent to Sklearn‚Äôs random test set splitter.&lt;/li&gt;
  &lt;li&gt;Uses NumPy to get permutation of the data (randomly sorted), then splits to at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_ratio&lt;/code&gt; and returns.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Behold, the Sklearn equivalent:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;housing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Notice that we can also use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;random_state&lt;/code&gt; param again for replicable randomness!&lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Sun, 30 Jul 2023 06:00:00 -0400</pubDate>
				<link>/2023/stratified-vs-random/</link>
				<guid isPermaLink="true">/2023/stratified-vs-random/</guid>
			</item>
		
			<item>
				<title>First Post!</title>
				<description>&lt;h2 id=&quot;heavy-inspired-by-minnowos-jekyll-site-catfish&quot;&gt;Heavy inspired by Minnowo‚Äôs Jekyll Site; ‚Äúcatfish‚Äù&lt;/h2&gt;

&lt;p&gt;I essentially forked it, and made my own changes &lt;em&gt;(Removed favicon, Edited navbar, Style tweaks, etc‚Ä¶)&lt;/em&gt;&lt;br /&gt;&lt;br /&gt;
&lt;strong&gt;Link:&lt;/strong&gt; &lt;a href=&quot;https://github.com/Minnowo/minnowo.github.io/tree/main&quot;&gt;Minnowo.github.io‚Äôs Source Repository&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Link to Site&lt;/strong&gt; &lt;a href=&quot;https://minnowo.github.io/2023/jekyll-deploy-struggle/&quot;&gt;https://minnowo.github.io/2023/jekyll-deploy-struggle/&lt;/a&gt; (VERY USEFUL LINK)&lt;/p&gt;

&lt;h2 id=&quot;note&quot;&gt;NOTE:&lt;/h2&gt;
&lt;p&gt;Make your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;username&amp;gt;.github.io&lt;/code&gt; Repository on Github Website! &lt;br /&gt; Initially I made it using the Linux &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gh&lt;/code&gt; pkg, and used &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gh repo create jasonmzx.github.io&lt;/code&gt; and it &lt;strong&gt;DID NOT WORK&lt;/strong&gt; during production. &lt;em&gt;(GitHub Actions was choking)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;After I re-created it on GitHub site, It auto-deployed immediately and worked like a charm!&lt;/p&gt;

</description>
				<pubDate>Sat, 22 Jul 2023 07:49:00 -0400</pubDate>
				<link>/2023/first-post/</link>
				<guid isPermaLink="true">/2023/first-post/</guid>
			</item>
		
	</channel>
</rss>
